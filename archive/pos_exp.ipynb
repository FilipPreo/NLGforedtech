{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-d35c46f8d1a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch'"
     ]
    }
   ],
   "source": [
    "import pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/flatironschool/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# testing lib fn\n",
    "from __future__ import print_function, unicode_literals\n",
    "from unicodedata import normalize\n",
    "import library_py2 as lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc\n",
    "# from sklearn.model_selection import traintestsplit\n",
    "# from sklearn.preprocessing import \n",
    "import json\n",
    "import warnings\n",
    "# from nltk.punkt impor\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer, wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.collocations import *\n",
    "from nltk import FreqDist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "warnings.filterwarnings(action='once')\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 999)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Masking\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('preprocessed_data2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>plausible_answers</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>context_lemma_pos</th>\n",
       "      <th>question_lemma_pos</th>\n",
       "      <th>answers_lemma_pos</th>\n",
       "      <th>plausible_answers_lemma_pos</th>\n",
       "      <th>context_lemma_pos_tfidf</th>\n",
       "      <th>question_lemma_pos_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(when, WRB), (beyonce, NN), (start, NN), (bec...</td>\n",
       "      <td>[(late, RB), (1990s, NNS)]</td>\n",
       "      <td></td>\n",
       "      <td>[(beyoncé, NN, 0.013333333333333334), (giselle...</td>\n",
       "      <td>[(when, WRB, 0.2), (beyonce, NN, 0.2), (start,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(what, WP), (area, NNS), (beyonce, VBP), (com...</td>\n",
       "      <td>[(sing, VBG), (dance, VBG)]</td>\n",
       "      <td></td>\n",
       "      <td>[(beyoncé, NN, 0.013333333333333334), (giselle...</td>\n",
       "      <td>[(what, WP, 0.2), (area, NNS, 0.2), (beyonce, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2003</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(when, WRB), (beyonce, NN), (leave, VBP), (de...</td>\n",
       "      <td>[(2003, CD)]</td>\n",
       "      <td></td>\n",
       "      <td>[(beyoncé, NN, 0.013333333333333334), (giselle...</td>\n",
       "      <td>[(when, WRB, 0.125), (beyonce, NN, 0.125), (le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(in, IN), (city, NN), (state, NN), (beyonce, ...</td>\n",
       "      <td>[(houston, NN), (texas, NN)]</td>\n",
       "      <td></td>\n",
       "      <td>[(beyoncé, NN, 0.013333333333333334), (giselle...</td>\n",
       "      <td>[(in, IN, 0.2), (city, NN, 0.2), (state, NN, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(in, IN), (decade, NN), (beyonce, NN), (becom...</td>\n",
       "      <td>[(late, RB), (1990s, NNS)]</td>\n",
       "      <td></td>\n",
       "      <td>[(beyoncé, NN, 0.013333333333333334), (giselle...</td>\n",
       "      <td>[(in, IN, 0.2), (decade, NN, 0.2), (beyonce, N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "\n",
       "                                            question              answers  \\\n",
       "0           When did Beyonce start becoming popular?    in the late 1990s   \n",
       "1  What areas did Beyonce compete in when she was...  singing and dancing   \n",
       "2  When did Beyonce leave Destiny's Child and bec...                 2003   \n",
       "3      In what city and state did Beyonce  grow up?        Houston, Texas   \n",
       "4         In which decade did Beyonce become famous?           late 1990s   \n",
       "\n",
       "  plausible_answers  is_impossible  \\\n",
       "0                                0   \n",
       "1                                0   \n",
       "2                                0   \n",
       "3                                0   \n",
       "4                                0   \n",
       "\n",
       "                                   context_lemma_pos  \\\n",
       "0  [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "1  [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "2  [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "3  [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "4  [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "\n",
       "                                  question_lemma_pos  \\\n",
       "0  [(when, WRB), (beyonce, NN), (start, NN), (bec...   \n",
       "1  [(what, WP), (area, NNS), (beyonce, VBP), (com...   \n",
       "2  [(when, WRB), (beyonce, NN), (leave, VBP), (de...   \n",
       "3  [(in, IN), (city, NN), (state, NN), (beyonce, ...   \n",
       "4  [(in, IN), (decade, NN), (beyonce, NN), (becom...   \n",
       "\n",
       "              answers_lemma_pos plausible_answers_lemma_pos  \\\n",
       "0    [(late, RB), (1990s, NNS)]                               \n",
       "1   [(sing, VBG), (dance, VBG)]                               \n",
       "2                  [(2003, CD)]                               \n",
       "3  [(houston, NN), (texas, NN)]                               \n",
       "4    [(late, RB), (1990s, NNS)]                               \n",
       "\n",
       "                             context_lemma_pos_tfidf  \\\n",
       "0  [(beyoncé, NN, 0.013333333333333334), (giselle...   \n",
       "1  [(beyoncé, NN, 0.013333333333333334), (giselle...   \n",
       "2  [(beyoncé, NN, 0.013333333333333334), (giselle...   \n",
       "3  [(beyoncé, NN, 0.013333333333333334), (giselle...   \n",
       "4  [(beyoncé, NN, 0.013333333333333334), (giselle...   \n",
       "\n",
       "                            question_lemma_pos_tfidf  \n",
       "0  [(when, WRB, 0.2), (beyonce, NN, 0.2), (start,...  \n",
       "1  [(what, WP, 0.2), (area, NNS, 0.2), (beyonce, ...  \n",
       "2  [(when, WRB, 0.125), (beyonce, NN, 0.125), (le...  \n",
       "3  [(in, IN, 0.2), (city, NN, 0.2), (state, NN, 0...  \n",
       "4  [(in, IN, 0.2), (decade, NN, 0.2), (beyonce, N...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130319"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.is_impossible==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86821"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschool/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['answer_len']=df.answers_lemma_pos.apply(lambda x: len(x))\n",
    "df['question_len']=df.question_lemma_pos.apply(lambda x: len(x))\n",
    "df['context_len']=df.context_lemma_pos.apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['context_lemma_pos_tfidf', 'question_lemma_pos_tfidf', 'plausible_answers', 'plausible_answers_lemma_pos', 'answers', 'question','context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>context_lemma_pos</th>\n",
       "      <th>question_lemma_pos</th>\n",
       "      <th>answers_lemma_pos</th>\n",
       "      <th>answer_len</th>\n",
       "      <th>question_len</th>\n",
       "      <th>context_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(when, WRB), (beyonce, NN), (start, NN), (bec...</td>\n",
       "      <td>[(late, RB), (1990s, NNS)]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(what, WP), (area, NNS), (beyonce, VBP), (com...</td>\n",
       "      <td>[(sing, VBG), (dance, VBG)]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(when, WRB), (beyonce, NN), (leave, VBP), (de...</td>\n",
       "      <td>[(2003, CD)]</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(in, IN), (city, NN), (state, NN), (beyonce, ...</td>\n",
       "      <td>[(houston, NN), (texas, NN)]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(in, IN), (decade, NN), (beyonce, NN), (becom...</td>\n",
       "      <td>[(late, RB), (1990s, NNS)]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_impossible                                  context_lemma_pos  \\\n",
       "0              0  [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "1              0  [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "2              0  [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "3              0  [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "4              0  [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "\n",
       "                                  question_lemma_pos  \\\n",
       "0  [(when, WRB), (beyonce, NN), (start, NN), (bec...   \n",
       "1  [(what, WP), (area, NNS), (beyonce, VBP), (com...   \n",
       "2  [(when, WRB), (beyonce, NN), (leave, VBP), (de...   \n",
       "3  [(in, IN), (city, NN), (state, NN), (beyonce, ...   \n",
       "4  [(in, IN), (decade, NN), (beyonce, NN), (becom...   \n",
       "\n",
       "              answers_lemma_pos  answer_len  question_len  context_len  \n",
       "0    [(late, RB), (1990s, NNS)]           2             5           75  \n",
       "1   [(sing, VBG), (dance, VBG)]           2             5           75  \n",
       "2                  [(2003, CD)]           1             8           75  \n",
       "3  [(houston, NN), (texas, NN)]           2             5           75  \n",
       "4    [(late, RB), (1990s, NNS)]           2             5           75  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['is_impossible'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_pos_W = df.loc[df.answer_len==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2         [(when, WRB), (beyonce, NN), (leave, VBP), (de...\n",
       "11        [(when, WRB), (beyoncé, NN), (release, NN), (d...\n",
       "12        [(how, WRB), (many, JJ), (grammy, JJ), (award,...\n",
       "15        [(after, IN), (second, JJ), (solo, NN), (album...\n",
       "17        [(to, TO), (set, VB), (record, NN), (grammys, ...\n",
       "                                ...                        \n",
       "130044    [(from, IN), (city, NN), (arkefly, NN), (offer...\n",
       "130046    [(in, IN), (us, PRP), (state, NN), (kathmandu,...\n",
       "130047    [(what, WP), (yangon, VBZ), (previously, RB), ...\n",
       "130048    [(with, IN), (belorussian, JJ), (city, NN), (k...\n",
       "130049    [(in, IN), (year, NN), (kathmandu, NN), (creat...\n",
       "Name: question_lemma_pos, Length: 31989, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_pos_W.question_lemma_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0.0,\n",
       " 'NN': 0.9592715737637746,\n",
       " 'VBP': 0.360315972751275,\n",
       " 'JJ': 0.927388867444324,\n",
       " 'CD': 0.7224863933266896,\n",
       " 'NNS': 0.8598924378549789,\n",
       " 'VBD': 0.9558813218777534,\n",
       " 'VBG': 0.4588106026733826,\n",
       " 'RB': 0.8611914183331262,\n",
       " 'VBZ': 0.6961802733464587,\n",
       " 'VBN': 0.6132534909840617,\n",
       " 'PRP$': 0.4684079411393567,\n",
       " 'VB': 0.07087393936983433,\n",
       " 'DT': 0.1976010461289125,\n",
       " 'PRP': 0.48297460721994667,\n",
       " 'JJR': 0.9573565640048951,\n",
       " 'IN': 0.9205742559261008,\n",
       " 'JJS': 0.022584915446127063,\n",
       " 'NNP': 0.7180885585022406,\n",
       " 'MD': 0.12392201019381988,\n",
       " 'WDT': 0.26916270907838447,\n",
       " 'FW': 0.35981720808378537,\n",
       " '$': 0.9628612911409422,\n",
       " 'WRB': 0.6699031132055633,\n",
       " 'RP': 0.22522257785126742,\n",
       " 'RBR': 0.3444770078816314,\n",
       " 'TO': 0.8305390934361616,\n",
       " 'RBS': 0.20702044303076117,\n",
       " 'CC': 0.16964627591060644,\n",
       " 'WP$': 0.13086722306185827,\n",
       " 'WP': 0.7444226774856989,\n",
       " 'EX': 0.38431416596916834,\n",
       " 'NNPS': 0.8220249472354502,\n",
       " 'PDT': 0.1729198618724923,\n",
       " 'SYM': 0.7412727310019118,\n",
       " 'POS': 0.6552685606251134,\n",
       " 'UH': 0.2943926076847583}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict=lib.get_pos_dict(df1_pos_W,columns=['context_lemma_pos'])\n",
    "pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31989"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1_pos_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_pos_W.to_pickle('df1_pos_W.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
