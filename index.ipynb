{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP for Ed-tech answer / question generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href = 'contents'></a>\n",
    "### Contents:\n",
    "\n",
    "[1. Introduction](#intro)\n",
    "\n",
    "[2. Theoretical background](#theory)\n",
    "\n",
    "[3. Cleaning, preprocessing and feature engineering](#clean)\n",
    "\n",
    "[4. Model selection and design](#modelselection)\n",
    "\n",
    "[5. Modelling the answer generator](#answer_gen)\n",
    "\n",
    "[5.1. Model training and validation](#answer_gen_train)\n",
    "\n",
    "[5.2 Model testing](#answer_gen_test)\n",
    "\n",
    "[6. Modelling the question generator](#question_gen)\n",
    "\n",
    "[6.1. Model training and validation](#question_gen_train)\n",
    "\n",
    "[6.2 Model testing](#question_gen_test)\n",
    "\n",
    "[7. Concluding remarks](#conclusion)\n",
    "\n",
    "[8. Bibliography](#bib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent advances in the field of Natural Language Processing (NLP) have generated novel ideas for technical applications in a variety of fields. One domain that stands to benefit greatly from recent models is educational technology (edtech) and, by extension, all educational providers. For many edtech platforms a key deliverable is assessment content, which is most likely painstakingly made by human experts, with multiple, plausible answers written in. Much of an edtech's content creating will be as automated as possible, but the complex, human-dependant element of generating comprehension questions and plausible answers that test for a (human) learner's understanding is often deemed too difficult for an edtech company to implement. There are two key tasks that, for the moment, seem too human for a machine to perform: 1. writing a question about a paragraph of text (our document) and 2. writing several equally plausible answers, with only one of them being detectable as the truly correct answer to a human expert. \n",
    "\n",
    "The first task is in the domain of Natural Language Generation (NLG) and the second is a Natural Language Understanding (NLU) task. In this notebook I've written up the process by which I've attempted to build two machine learners dedicated to accomplishing the two tasks above in a way that would be most useful to an edtech provider. Section 2 is my "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'theory'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theoretical background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'clean'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning, preprocessing and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the interactive nature of the desired end-product, cleaning and preprocessing had to be kept relatively minimal, and whenever necessary, kept modular. For instance, I initially discarded \"stop words\" (e.g. \"what\", \"of\", \"it\") but returned to include them later in the modelling process because I'd considered that such information would be more valuable to the learner.\n",
    "After extracting the data from the JSON file the text was stored inside a dataframe as 3 separate columns, with context paragraphs, the question and the answers. Attempting various different ways of engineering data, I decided to incorporate 3 different features:\n",
    "\n",
    "1. Allocate each word a Part of Sentence (POS) tag using NLTK's POS tagger\n",
    "2. Lemmatize each word using the WordNet lemmatizer\n",
    "3. Utilize pretrained word embeddings from Stanford's GloVe project[2](#2). \n",
    "\n",
    "The GloVe pretrained weights were available in 4 lengths of one-column vectors (50, 100, 200, 300) and in order to translate the POS tag into a weight I added an extra element to each of those vectors for the POS tags (shown two cells below). Directly below is a slice of the dataframe as it looked at this point in time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_lemma_pos</th>\n",
       "      <th>question_lemma_pos</th>\n",
       "      <th>answers_lemma_pos</th>\n",
       "      <th>answer_len</th>\n",
       "      <th>question_len</th>\n",
       "      <th>context_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(when, WRB), (beyonce, NN), (leave, VBP), (de...</td>\n",
       "      <td>[(2003, CD)]</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(when, WRB), (beyoncé, NN), (release, NN), (d...</td>\n",
       "      <td>[(2003, CD)]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(how, WRB), (many, JJ), (grammy, JJ), (award,...</td>\n",
       "      <td>[(five, CD)]</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>[(follow, VBG), (disbandment, NN), (destiny, N...</td>\n",
       "      <td>[(after, IN), (second, JJ), (solo, NN), (album...</td>\n",
       "      <td>[(act, VBG)]</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>[(follow, VBG), (disbandment, NN), (destiny, N...</td>\n",
       "      <td>[(to, TO), (set, VB), (record, NN), (grammys, ...</td>\n",
       "      <td>[(six, CD)]</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    context_lemma_pos  \\\n",
       "2   [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "11  [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "12  [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "15  [(follow, VBG), (disbandment, NN), (destiny, N...   \n",
       "17  [(follow, VBG), (disbandment, NN), (destiny, N...   \n",
       "\n",
       "                                   question_lemma_pos answers_lemma_pos  \\\n",
       "2   [(when, WRB), (beyonce, NN), (leave, VBP), (de...      [(2003, CD)]   \n",
       "11  [(when, WRB), (beyoncé, NN), (release, NN), (d...      [(2003, CD)]   \n",
       "12  [(how, WRB), (many, JJ), (grammy, JJ), (award,...      [(five, CD)]   \n",
       "15  [(after, IN), (second, JJ), (solo, NN), (album...      [(act, VBG)]   \n",
       "17  [(to, TO), (set, VB), (record, NN), (grammys, ...       [(six, CD)]   \n",
       "\n",
       "    answer_len  question_len  context_len  \n",
       "2            1             8           75  \n",
       "11           1             5           75  \n",
       "12           1             9           75  \n",
       "15           1             8          112  \n",
       "17           1             7          112  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('df1_pos_W.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0.0,\n",
       " 'NN': 0.08078729573077403,\n",
       " 'VBP': 0.43049489205603175,\n",
       " 'JJ': 0.22627048703939012,\n",
       " 'CD': 0.782025845371569,\n",
       " 'NNS': 0.7196239018674129,\n",
       " 'VBD': 0.43316906320635873,\n",
       " 'VBG': 0.2738475150287274,\n",
       " 'RB': 0.12437301301267711,\n",
       " 'VBZ': 0.9574997725141698,\n",
       " 'VBN': 0.6235842224079152,\n",
       " 'PRP$': 0.7594464769150902,\n",
       " 'VB': 0.5933595139266659,\n",
       " 'DT': 0.780331365792381,\n",
       " 'PRP': 0.21155649677086108,\n",
       " 'JJR': 0.08616271143743359,\n",
       " 'IN': 0.3159941099223168,\n",
       " 'JJS': 0.023459126356141446,\n",
       " 'NNP': 0.2589476751408578,\n",
       " 'MD': 0.31947113330180155,\n",
       " 'WDT': 0.2930305958336812,\n",
       " 'FW': 0.9362648530794228,\n",
       " '$': 0.25367766821903814,\n",
       " 'WRB': 0.9848137711349689,\n",
       " 'RP': 0.22819105986883026,\n",
       " 'RBR': 0.6478409439239122,\n",
       " 'TO': 0.21128814560671427,\n",
       " 'RBS': 0.036154152229286085,\n",
       " 'CC': 0.5883740392104109,\n",
       " 'WP$': 0.3022983423385648,\n",
       " 'WP': 0.2606244819690704,\n",
       " 'EX': 0.5138941380588374,\n",
       " 'NNPS': 0.5506818065967534,\n",
       " 'PDT': 0.542542421914276,\n",
       " 'SYM': 0.16669352976733498,\n",
       " 'POS': 0.17299372118613776,\n",
       " 'UH': 0.8385352014992612,\n",
       " 'LS': 0.004647097353534413}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict = lib.get_pos_dict(df)\n",
    "pos_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words were fed in as concatenations of the word and the POS tag (e.g.\"leave_VBP\"), as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_lemma_pos</th>\n",
       "      <th>question_lemma_pos</th>\n",
       "      <th>answers_lemma_pos</th>\n",
       "      <th>answer_len</th>\n",
       "      <th>question_len</th>\n",
       "      <th>context_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>130044</td>\n",
       "      <td>the_DT main_JJ international_JJ airport_NN ser...</td>\n",
       "      <td>from_IN city_NN arkefly_NN offer_VBP nonstop_J...</td>\n",
       "      <td>amsterdam_NN</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130046</td>\n",
       "      <td>kathmandu_JJ metropolitan_JJ city_NN kmc_NN or...</td>\n",
       "      <td>in_IN us_PRP state_NN kathmandu_VBD first_JJ e...</td>\n",
       "      <td>oregon_NN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130047</td>\n",
       "      <td>kathmandu_JJ metropolitan_JJ city_NN kmc_NN or...</td>\n",
       "      <td>what_WP yangon_VBZ previously_RB know_VBN</td>\n",
       "      <td>rangoon_NN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130048</td>\n",
       "      <td>kathmandu_JJ metropolitan_JJ city_NN kmc_NN or...</td>\n",
       "      <td>with_IN belorussian_JJ city_NN kathmandu_NN re...</td>\n",
       "      <td>minsk_NN</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130049</td>\n",
       "      <td>kathmandu_JJ metropolitan_JJ city_NN kmc_NN or...</td>\n",
       "      <td>in_IN year_NN kathmandu_NN create_VBP initial_...</td>\n",
       "      <td>1975_CD</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        context_lemma_pos  \\\n",
       "130044  the_DT main_JJ international_JJ airport_NN ser...   \n",
       "130046  kathmandu_JJ metropolitan_JJ city_NN kmc_NN or...   \n",
       "130047  kathmandu_JJ metropolitan_JJ city_NN kmc_NN or...   \n",
       "130048  kathmandu_JJ metropolitan_JJ city_NN kmc_NN or...   \n",
       "130049  kathmandu_JJ metropolitan_JJ city_NN kmc_NN or...   \n",
       "\n",
       "                                       question_lemma_pos answers_lemma_pos  \\\n",
       "130044  from_IN city_NN arkefly_NN offer_VBP nonstop_J...      amsterdam_NN   \n",
       "130046  in_IN us_PRP state_NN kathmandu_VBD first_JJ e...         oregon_NN   \n",
       "130047          what_WP yangon_VBZ previously_RB know_VBN        rangoon_NN   \n",
       "130048  with_IN belorussian_JJ city_NN kathmandu_NN re...          minsk_NN   \n",
       "130049  in_IN year_NN kathmandu_NN create_VBP initial_...           1975_CD   \n",
       "\n",
       "        answer_len  question_len  context_len  \n",
       "130044           1             7          103  \n",
       "130046           1             8           71  \n",
       "130047           1             4           71  \n",
       "130048           1             5           71  \n",
       "130049           1             7           71  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = lib.concat_word_pos(df, columns=['context_lemma_pos', 'question_lemma_pos','answers_lemma_pos'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our total vocabulary size is 127983, consisting of unique word and POS combinations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = lib.get_total_vocab(df, columns=['context_lemma_pos', 'question_lemma_pos'])\n",
    "df['text'] = df['context_lemma_pos'] + ' ' + df['question_lemma_pos']\n",
    "df['question_answer'] = df['question_lemma_pos'] + ' ' + df['answers_lemma_pos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'modelselection'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model selection and design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'answer_gen'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling the answer generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'answer_gen_train'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Model training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'answer_gen_test'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2  Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'question_gen'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modelling the question generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'question_gen_train'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Model training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'question_gen_test'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'conclusion'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Concluding remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'bib'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=1 ></a>\n",
    "1. Stanford Natural Language Processing Group - Questions and Answers Dataset (SQuAD) - https://rajpurkar.github.io/SQuAD-explorer/ \n",
    "<a id=2 ></a>\n",
    "2. Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation\n",
    "<a id=3 ></a>\n",
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/flatironschool/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, unicode_literals\n",
    "from unicodedata import normalize\n",
    "import library_py2 as lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import warnings\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer, wordnet\n",
    "import re\n",
    "warnings.filterwarnings(action='once')\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Masking, Dropout, TimeDistributed\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
