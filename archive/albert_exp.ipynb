{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2136, 0.6029, 0.7014],\n",
      "        [0.8107, 0.1225, 0.3021],\n",
      "        [0.4463, 0.6701, 0.9434],\n",
      "        [0.9879, 0.8220, 0.3606],\n",
      "        [0.5320, 0.2842, 0.3815]])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/flatironschool/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# testing lib fn\n",
    "from __future__ import print_function, unicode_literals\n",
    "from unicodedata import normalize\n",
    "import library_py2 as lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc\n",
    "# from sklearn.model_selection import traintestsplit\n",
    "# from sklearn.preprocessing import \n",
    "import json\n",
    "import warnings\n",
    "# from nltk.punkt impor\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer, wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.collocations import *\n",
    "from nltk import FreqDist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "warnings.filterwarnings(action='once')\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 999)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Masking\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df1_pos_W.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_lemma_pos</th>\n",
       "      <th>question_lemma_pos</th>\n",
       "      <th>answers_lemma_pos</th>\n",
       "      <th>answer_len</th>\n",
       "      <th>question_len</th>\n",
       "      <th>context_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(when, WRB), (beyonce, NN), (leave, VBP), (de...</td>\n",
       "      <td>[(2003, CD)]</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(when, WRB), (beyoncé, NN), (release, NN), (d...</td>\n",
       "      <td>[(2003, CD)]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>[(beyoncé, NN), (giselle, NN), (knowlescarter,...</td>\n",
       "      <td>[(how, WRB), (many, JJ), (grammy, JJ), (award,...</td>\n",
       "      <td>[(five, CD)]</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>[(follow, VBG), (disbandment, NN), (destiny, N...</td>\n",
       "      <td>[(after, IN), (second, JJ), (solo, NN), (album...</td>\n",
       "      <td>[(act, VBG)]</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>[(follow, VBG), (disbandment, NN), (destiny, N...</td>\n",
       "      <td>[(to, TO), (set, VB), (record, NN), (grammys, ...</td>\n",
       "      <td>[(six, CD)]</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    context_lemma_pos  \\\n",
       "2   [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "11  [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "12  [(beyoncé, NN), (giselle, NN), (knowlescarter,...   \n",
       "15  [(follow, VBG), (disbandment, NN), (destiny, N...   \n",
       "17  [(follow, VBG), (disbandment, NN), (destiny, N...   \n",
       "\n",
       "                                   question_lemma_pos answers_lemma_pos  \\\n",
       "2   [(when, WRB), (beyonce, NN), (leave, VBP), (de...      [(2003, CD)]   \n",
       "11  [(when, WRB), (beyoncé, NN), (release, NN), (d...      [(2003, CD)]   \n",
       "12  [(how, WRB), (many, JJ), (grammy, JJ), (award,...      [(five, CD)]   \n",
       "15  [(after, IN), (second, JJ), (solo, NN), (album...      [(act, VBG)]   \n",
       "17  [(to, TO), (set, VB), (record, NN), (grammys, ...       [(six, CD)]   \n",
       "\n",
       "    answer_len  question_len  context_len  \n",
       "2            1             8           75  \n",
       "11           1             5           75  \n",
       "12           1             9           75  \n",
       "15           1             8          112  \n",
       "17           1             7          112  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31989"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2         [(when, WRB), (beyonce, NN), (leave, VBP), (de...\n",
       "11        [(when, WRB), (beyoncé, NN), (release, NN), (d...\n",
       "12        [(how, WRB), (many, JJ), (grammy, JJ), (award,...\n",
       "15        [(after, IN), (second, JJ), (solo, NN), (album...\n",
       "17        [(to, TO), (set, VB), (record, NN), (grammys, ...\n",
       "                                ...                        \n",
       "130044    [(from, IN), (city, NN), (arkefly, NN), (offer...\n",
       "130046    [(in, IN), (us, PRP), (state, NN), (kathmandu,...\n",
       "130047    [(what, WP), (yangon, VBZ), (previously, RB), ...\n",
       "130048    [(with, IN), (belorussian, JJ), (city, NN), (k...\n",
       "130049    [(in, IN), (year, NN), (kathmandu, NN), (creat...\n",
       "Name: question_lemma_pos, Length: 31989, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.question_lemma_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0.0,\n",
       " 'NN': 0.9396290695832222,\n",
       " 'VBP': 0.6481191750452352,\n",
       " 'JJ': 0.05336812937575197,\n",
       " 'CD': 0.3325599466223039,\n",
       " 'NNS': 0.1908087792008828,\n",
       " 'VBD': 0.9282145062504379,\n",
       " 'VBG': 0.5582149791824439,\n",
       " 'RB': 0.9694721332405776,\n",
       " 'VBZ': 0.2231554698427548,\n",
       " 'VBN': 0.6755873747134403,\n",
       " 'PRP$': 0.7388765498478684,\n",
       " 'VB': 0.010894167732162674,\n",
       " 'DT': 0.7572363251420033,\n",
       " 'PRP': 0.489629885242439,\n",
       " 'JJR': 0.264321492287111,\n",
       " 'IN': 0.05726307181474455,\n",
       " 'JJS': 0.1943286222958902,\n",
       " 'NNP': 0.4110884066302938,\n",
       " 'MD': 0.19010961518913128,\n",
       " 'WDT': 0.25797421394306674,\n",
       " 'FW': 0.2029404303436384,\n",
       " '$': 0.7207393953877647,\n",
       " 'WRB': 0.15018010009942107,\n",
       " 'RP': 0.3412654226213009,\n",
       " 'RBR': 0.7220541548278566,\n",
       " 'TO': 0.38743332497416905,\n",
       " 'RBS': 0.5365336483567881,\n",
       " 'CC': 0.9896245981926637,\n",
       " 'WP$': 0.0886279399098866,\n",
       " 'WP': 0.7261817587059886,\n",
       " 'EX': 0.3419149946459943,\n",
       " 'NNPS': 0.6571860596137962,\n",
       " 'PDT': 0.3730334532730085,\n",
       " 'SYM': 0.21167556750789263,\n",
       " 'POS': 0.9148450236064504,\n",
       " 'UH': 0.5113019937688846}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict=lib.get_pos_dict(df,columns=['context_lemma_pos', 'question_lemma_pos'])\n",
    "pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
